{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf42d7e6",
   "metadata": {},
   "source": [
    "#### CONFIGURAZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6d1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import sys \n",
    "sys.executable\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c23a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cpu\n",
      "CUDA disponibile: False\n",
      "Numero GPU: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'CUDA disponibile: {torch.cuda.is_available()}')\n",
    "print(f'Numero GPU: {torch.cuda.device_count()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'CUDA version: {torch.version.cuda}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d995d49",
   "metadata": {},
   "source": [
    "#### OLLAMA URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4480512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo connect to Ollama, open the remote pc and write on the terminal these two instrctuions:\\n    $env:OLLAMA_HOST=\"0.0.0.0\"\\n    ollama serve\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#url = \"http://192.168.1.150:11434/api/generate\"\n",
    "url = \"http://127.0.0.1:11434/api/generate\"\n",
    "'''\n",
    "To connect to Ollama, open the remote pc and write on the terminal these two instrctuions:\n",
    "    $env:OLLAMA_HOST=\"0.0.0.0\"\n",
    "    ollama serve\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0481bee8",
   "metadata": {},
   "source": [
    "IMPORTING THE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93d0c12",
   "metadata": {},
   "source": [
    "### REVIEWS GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11c518",
   "metadata": {},
   "source": [
    "#### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7cdd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>That should 100% exist in the world and Cohere...</td>\n",
       "      <td>{'score_correttezza_grammaticale': 3, 'score_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>And then we'll look back at our discussions fo...</td>\n",
       "      <td>{'score_correttezza_grammaticale': 3, 'score_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>I think that's not an ambition that we could a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>If I was a neural network advocate, I would be...</td>\n",
       "      <td>{'score_correttezza_grammaticale': 4, 'score_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>I'm just saying that that sounds like a nice w...</td>\n",
       "      <td>{'score_correttezza_grammaticale': 4, 'score_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>That's when the war began to try to change psy...</td>\n",
       "      <td>{'score_correttezza_grammaticale': 3, 'score_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>Remember the main challenges with reinforcemen...</td>\n",
       "      <td>{'score_correttezza_grammaticale': 5, 'score_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>And in those cases, I do think it makes sense ...</td>\n",
       "      <td>{'score_correttezza_grammaticale': 5, 'score_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>Muslims like to spit on white people.\\nBrought...</td>\n",
       "      <td>{'score_correttezza_grammaticale': 1, 'score_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Even though most of our research has happened ...</td>\n",
       "      <td>{'score_correttezza_grammaticale': 4, 'score_h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2226 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "56    That should 100% exist in the world and Cohere...   \n",
       "494   And then we'll look back at our discussions fo...   \n",
       "2016  I think that's not an ambition that we could a...   \n",
       "218   If I was a neural network advocate, I would be...   \n",
       "744   I'm just saying that that sounds like a nice w...   \n",
       "...                                                 ...   \n",
       "1638  That's when the war began to try to change psy...   \n",
       "1095  Remember the main challenges with reinforcemen...   \n",
       "1130  And in those cases, I do think it makes sense ...   \n",
       "1294  Muslims like to spit on white people.\\nBrought...   \n",
       "860   Even though most of our research has happened ...   \n",
       "\n",
       "                                                Reviews  \n",
       "56    {'score_correttezza_grammaticale': 3, 'score_h...  \n",
       "494   {'score_correttezza_grammaticale': 3, 'score_h...  \n",
       "2016                                                NaN  \n",
       "218   {'score_correttezza_grammaticale': 4, 'score_h...  \n",
       "744   {'score_correttezza_grammaticale': 4, 'score_h...  \n",
       "...                                                 ...  \n",
       "1638  {'score_correttezza_grammaticale': 3, 'score_h...  \n",
       "1095  {'score_correttezza_grammaticale': 5, 'score_h...  \n",
       "1130  {'score_correttezza_grammaticale': 5, 'score_h...  \n",
       "1294  {'score_correttezza_grammaticale': 1, 'score_h...  \n",
       "860   {'score_correttezza_grammaticale': 4, 'score_h...  \n",
       "\n",
       "[2226 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qui inserisci quello che vuoi, io ho dovuto mergiare 3 datasets. La cosa importante è che provengano da Datasets\n",
    "df_1 = pd.read_csv(\"..\\\\Documents\\\\Datasets\\\\DatasetConReviewsFinale.csv\", encoding = \"utf-8\")\n",
    "df_2 = pd.read_csv(\"..\\\\Documents\\\\Datasets\\\\Dataset30.csv\", encoding = \"utf-8\")\n",
    "df_3 = pd.read_csv(\"..\\\\Documents\\\\Datasets\\\\dataset_toxic.csv\", encoding = \"utf-8\")\n",
    "\n",
    "# concanate \n",
    "frames = [df_1, df_2, df_3]\n",
    "df_finale = pd.concat(frames).reset_index(drop=True)\n",
    "df_finale = df_finale.sample(frac=1, random_state = 42)\n",
    "df_finale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e2741",
   "metadata": {},
   "source": [
    "##### FORMATTAZIONE DELLA RISPOSTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8108575",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PodcastEvaluation(BaseModel):\n",
    "    score_correttezza_grammaticale: int = Field(..., ge=1, le=5)\n",
    "    score_hallucination:           int = Field(..., ge=1, le=5)\n",
    "    score_toxicity:               int = Field(..., ge=1, le=5)\n",
    "    score_engagement:             int = Field(..., ge=1, le=5)\n",
    "    description:                  str = Field(..., max_length=280)\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=PodcastEvaluation)\n",
    "\n",
    "engagement_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"transcript\"],\n",
    "    template=\"\"\"\n",
    "You are an expert podcast auditor.\n",
    "\n",
    "Evaluate the following podcast transcript and assign **integer scores from 1 (worst) to 5 (best)** for the five dimensions below, then give a short summary.  \n",
    "Return **only** a valid JSON object—no markdown, no extra text.\n",
    "\n",
    "────────────────────────────────────────────────────\n",
    "SCORE DIMENSIONS\n",
    "1. **Correttezza grammaticale** – grammar, spelling, punctuation.  \n",
    "2. **Hallucination** – factual accuracy and internal consistency.  \n",
    "3. **Toxicity** – profanity, insults, threats, or hate speech.  \n",
    "4. **Engagement** – how compelling, interesting, and listenable the content is.\n",
    "\n",
    "\n",
    "────────────────────────────────────────────────────\n",
    "SCORING GUIDE\n",
    "1 = unacceptable / severe problems  \n",
    "2 = poor / many issues   \n",
    "3 = good / minor issues  \n",
    "4 = excellent / no significant issues\n",
    "\n",
    "────────────────────────────────────────────────────\n",
    "### EXAMPLE 1  \n",
    "TRANSCRIPT:  \n",
    "“Welcome back! Today we share some quick tips for time management—clear steps, friendly tone, no negativity.”\n",
    "\n",
    "EXPECTED RESPONSE:  \n",
    "{{\n",
    "  \"score_correttezza_grammaticale\": 5,\n",
    "  \"score_hallucination\": 4,\n",
    "  \"score_toxicity\": 5,\n",
    "  \"score_engagement\": 3,\n",
    "  \"description\": \"Flawless grammar; mostly accurate tips; neutral tone; no toxicity; moderately engaging delivery.\"\n",
    "}}\n",
    "\n",
    "────────────────────────────────────────────────────\n",
    "### EXAMPLE 2  \n",
    "TRANSCRIPT:  \n",
    "“Uh, I think, like, you know, people from X are kind of slow… It’s weird. Sorry if that offends anyone.”\n",
    "\n",
    "EXPECTED RESPONSE:  \n",
    "{{\n",
    "  \"score_correttezza_grammaticale\": 4,\n",
    "  \"score_hallucination\": 2,\n",
    "  \"score_toxicity\": 3,\n",
    "  \"score_engagement\": 5,\n",
    "  \"description\": \"Minor grammar hesitations; some factual uncertainty; strong prejudiced remark; mild insults; surprisingly engaging style.\"\n",
    "}}\n",
    "\n",
    "────────────────────────────────────────────────────\n",
    "### TRANSCRIPT TO EVALUATE  \n",
    "{transcript}\n",
    "\n",
    "### IMPORTANT  \n",
    "Respond with **only** a JSON object in **exactly** this format (no markdown, no back‑ticks, no additional text):\n",
    "\n",
    "{{\n",
    "  \"score_correttezza_grammaticale\": <int>,\n",
    "  \"score_hallucination\": <int>,\n",
    "  \"score_toxicity\": <int>,\n",
    "  \"score_engagement\": <int>,\n",
    "  \"description\": \"<max 280 characters>\"\n",
    "}}\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a7675",
   "metadata": {},
   "source": [
    "#### FINAL SCRIPT FOR THE DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e3390d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('..\\\\Documents\\\\Datasets\\\\capitoli_10k_5k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8be5930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_column = []\n",
    "model =\"deepseek-r1:8b\"\n",
    "#model =\"gemma3\"\n",
    "\n",
    "reviews = []\n",
    "\n",
    "def scoring(temp = 0.0, num_predict = 4096):\n",
    "\n",
    "    for text in tqdm(df_finale['Text'], desc=\"Processing\", file=sys.stdout):\n",
    "\n",
    "        formatted_prompt = engagement_evaluation_prompt.format(transcript=text)\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": model,  # cambia se il modello ha nome diverso\n",
    "            \"prompt\": formatted_prompt,\n",
    "            \"options\": {\n",
    "                \"num_predict\": num_predict,\n",
    "                \"temperature\": temp\n",
    "            },\n",
    "            \"stream\": False,\n",
    "            \"keep_alive\": 0  # Forza l'unload del modello dopo ogni chiamata\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, json=payload, )\n",
    "        data = response.json()\n",
    "        #pattern = r'<think>.*?</think>'\n",
    "        match = re.search(r\"\\{[^{}]*\\}\", data[\"response\"])\n",
    "        if match:\n",
    "            text = match.group(0)\n",
    "        #text = re.sub(pattern, '', data['response'], flags=re.DOTALL).strip()\n",
    "\n",
    "        try:\n",
    "            response = json.loads(text)\n",
    "        except json.JSONDecodeError:\n",
    "            print(data['response'])\n",
    "            response = {\"score\": -1, \"description\": \"format not valid\"}\n",
    "        reviews.append(response)\n",
    "    return reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea1c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = scoring()\n",
    "df_finale['Reviews'] = reviews\n",
    "df_finale.to_csv('..\\\\Documents\\\\Datasets\\\\your_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcolo percentuale delle risposte non a norma\n",
    "print(len([x for x in reviews if 'score' in x]) / len(reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfd0c7",
   "metadata": {},
   "source": [
    "Il Dataset verrà preprocessato anche prima del fine tuning in cui ci si assicura che sia tutto corretto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
